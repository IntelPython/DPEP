
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Heterogeneous computing &#8212; Data Parallel Extensions for Python* 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sdc.css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <script type="text/javascript" src="_static/copybutton.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Programming with Data Parallel Extensions for Python" href="programming_dpep.html" />
    <link rel="prev" title="Parallelism in modern data parallel architectures" href="parallelism.html" />
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,600' rel='stylesheet' type='text/css'/>

  </head><body>
<div class="topbar">
  <a class="brand" title="Intel Python projects" href="other_intel_python_projects.html"></a>
  <a class="brand_sdc" title="Documentation Home" href="index.html"></a>

  <ul>
    <li><a class="exampleslink" title="Examples" href="examples.html"></a></li>
    <li><a class="issueslink" title="Issues" href="https://community.intel.com/t5/Intel-Distribution-for-Python/bd-p/distribution-python"></a></li>
    <li><a class="emaillink" title="Email" href="mailto:scripting@intel.com"></a></li>
    <li><a class="homelink" title="GitHub" href="https://github.com/IntelPython/DPPY"></a></li>
    <li>
      
      
<form action="search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
      
    </li>
  </ul>
</div>

<div class="related">
    <h3>Navigation</h3>
    <ul>
      <li class="right">
	<a href="programming_dpep.html" title="Programming with Data Parallel Extensions for Python">
	  next &raquo;
	</a>
      </li>
      <li class="right">
	<a href="parallelism.html" title="Parallelism in modern data parallel architectures">
	  &laquo; previous
	</a>
	 |
      </li>
      <li>
	<a href="index.html">Data Parallel Extensions for Python* 0.1 documentation</a>
	 &#187;
      </li>
      
      <li>Heterogeneous computing</li> 
    </ul>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <span class="target" id="heterogeneous-computing"></span><section id="id1">
<h1>Heterogeneous computing<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<section id="device-offload">
<h2>Device Offload<a class="headerlink" href="#device-offload" title="Permalink to this heading">¶</a></h2>
<p>Python is an interpreted language, which implies that most of Python codes will run on CPU,
and only a few data parallel regions will execute on data parallel devices.
That is why the concept of host and offload devices is useful when it comes to conceptualizing
a heterogeneous programming model in Python.</p>
<a class="reference internal image-reference" href="_images/hetero-devices.png"><img alt="SIMD" class="align-center" src="_images/hetero-devices.png" style="width: 600px;" /></a>
<p>The above diagram illustrates the <em>host</em> (the CPU which runs Python interpreter) and three <em>devices</em>
(two GPU devices and one attached accelerator device). <strong>Data Parallel Extensions for Python</strong>
offer a programming model where a script executed by Python interpreter on host can <em>offload</em> data
parallel kernels to user-specified device. A <em>kernel</em> is the <em>data parallel region</em> of a program submitted
for execution on the device. There can be multiple data parallel regions, and hence multiple <em>offload kernels</em>.</p>
<p>Kernels can be pre-compiled into a library, such as <code class="docutils literal notranslate"><span class="pre">dpnp</span></code>, or, alternatively, directly coded
in a programming language for heterogeneous computing, such as <a class="reference external" href="https://www.khronos.org/opencl/">OpenCl*</a> or <a class="reference external" href="https://www.apress.com/gp/book/9781484255735">DPC++</a> .
<strong>Data Parallel Extensions for Python</strong> offer the way of writing kernels directly in Python
using <a class="reference external" href="https://numba.pydata.org/">Numba*</a> compiler along with <code class="docutils literal notranslate"><span class="pre">numba-dpex</span></code>, the <a class="reference external" href="https://intelpython.github.io/numba-dpex/latest/index.html">Data Parallel Extension for Numba*</a>.</p>
<p>One or more kernels are submitted for execution into a <em>queue</em> targeting an <em>offload device</em>.
For each device one or more queues can be created. In most cases you won’t need to work
with device queues directly. Data Parallel Extensions for Python will do necessary underlying
work with queues for you through the <a class="reference internal" href="#compute-follows-data"><span class="std std-ref">Compute-Follows-Data</span></a>.</p>
</section>
<section id="unified-shared-memory">
<h2>Unified Shared Memory<a class="headerlink" href="#unified-shared-memory" title="Permalink to this heading">¶</a></h2>
<p>Each device has its own memory, not necessarily accessible from another device.</p>
<a class="reference internal image-reference" href="_images/hetero-devices.png"><img alt="SIMD" class="align-center" src="_images/hetero-devices.png" style="width: 600px;" /></a>
<p>For example, <strong>Device 1</strong> memory may not be directly accessible from the host, but only accessible
via expensive copying by a driver software. Similarly, depending on the architecture, direct data
exchange between <strong>Device 2</strong> and <strong>Device 1</strong> may be impossible, and only possible via expensive
copying through the host memory. These aspects must be taken into consideration when programming
data parallel devices.</p>
<p>In the above illustration the <strong>Device 2</strong> logically consists of two sub-devices, <strong>Sub-Device 1</strong>
and <strong>Sub-Device 2</strong>. The programming model allows accessing <strong>Device 2</strong> as a single logical device, or
by working with each individual sub-devices. For the former case a programmer needs to create
a queue for <strong>Device 2</strong>. For the latter case a programmer needs to create 2 queues, one for each sub-device.</p>
<p><a class="reference external" href="https://www.khronos.org/sycl/">SYCL*</a> standard introduces a concept of the <em>Unified Shared Memory</em> (USM). USM requires hardware support
for unified virtual address space, which allows coherency between the host and the device
pointers. All memory is allocated by the host, but it offers three distinct allocation types:</p>
<ul class="simple">
<li><p><strong>Host: located on the host, accessible by the host or device.</strong> This type of memory is useful in a situation
when you need to stream a read-only data from the host to the device once.</p></li>
<li><p><strong>Device: located on the device, accessibly only by the device.</strong> This type of memory is the fastest one.
Useful in a situation when most of data crunching happens on the device.</p></li>
<li><p><strong>Shared: location is both host and device (copies are synchronized by underlying software), accessible by
the host or device.</strong> Shared allocations are useful when data are accessed by both host and devices,
since a user does not need to explicitly manage data migration. However, it is much slower than USM Device memory type.</p></li>
</ul>
</section>
<section id="compute-follows-data">
<h2>Compute-Follows-Data<a class="headerlink" href="#compute-follows-data" title="Permalink to this heading">¶</a></h2>
<p>Since data copying between devices is typically very expensive, for performance reasons it is essential
to process data close to where it is allocated. This is the premise of the <em>Compute-Follows-Data</em> programming model,
which states that the compute will happen where the data resides. Tensors implemented in <code class="docutils literal notranslate"><span class="pre">dpctl</span></code> and <code class="docutils literal notranslate"><span class="pre">dpnp</span></code>
carry information about allocation queues, and hence, about the device on which an array is allocated.
Based on tensor input arguments of the offload kernel, it deduces the queue on which the execution takes place.</p>
<a class="reference internal image-reference" href="_images/kernel-queue-device.png"><img alt="SIMD" class="align-center" src="_images/kernel-queue-device.png" style="width: 600px;" /></a>
<p>The above picture illustrates the <em>Compute-Follows-Data</em> concept. Arrays <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are inputs to the
<strong>Offload Kernel</strong>. These arrays carry information about their <em>allocation queue</em> (<strong>Device Queue</strong>) and the
<em>device</em> (<strong>Device 1</strong>) where they were created. According to the Compute-Follows-Data paradigm
the <strong>Offload Kernel</strong> will be submitted to this <strong>Device Queue</strong>, and the resulting array <code class="docutils literal notranslate"><span class="pre">C</span></code> will
be created on the <strong>Device Queue</strong> associated with the <strong>Device 1</strong>.</p>
<p><strong>Data Parallel Extensions for Python</strong> require all input tensor arguments to have the <strong>same</strong> allocation queue,
otherwise an exception will be thrown. For example, the following usages will result in the exception.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="_images/queue-exception1.png"><img alt="SIMD" src="_images/queue-exception1.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-text">Input tensors are on different devices and different queues. Exception is thrown.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="_images/queue-exception2.png"><img alt="SIMD" src="_images/queue-exception2.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-text">Input tensors are on the same device but queues are different. Exception is thrown.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="_images/queue-exception3.png"><img alt="SIMD" src="_images/queue-exception3.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-text">Data belongs to the same device, but queues are different and associated with different sub-devices.</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="copying-data-between-devices-and-queues">
<h2>Copying data between devices and queues<a class="headerlink" href="#copying-data-between-devices-and-queues" title="Permalink to this heading">¶</a></h2>
<p><strong>Data Parallel Extensions for Python</strong> create <strong>one</strong> <em>canonical queue</em> per device so that in
normal circumstances you do not need to directly manage queues. Having one canonical queue per device
allows you to copy data between devices using to_device() method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a_new</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Array <code class="docutils literal notranslate"><span class="pre">a</span></code> will be copied to the device associated with array <code class="docutils literal notranslate"><span class="pre">b</span></code> into the new array <code class="docutils literal notranslate"><span class="pre">a_new</span></code>.
The same queue will be associated with <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">a_new</span></code>.</p>
<p>Alternatively, you can do this as follows:</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">DPNP array</span><a class="headerlink" href="#id5" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a_new</span> <span class="o">=</span> <span class="n">dpnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">b</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">DPCtl array</span><a class="headerlink" href="#id6" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a_new</span> <span class="o">=</span> <span class="n">dpctl</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">b</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="creating-additional-queues">
<h2>Creating additional queues<a class="headerlink" href="#creating-additional-queues" title="Permalink to this heading">¶</a></h2>
<p>As previously indicated <strong>Data Parallel Extensions for Python</strong> automatically create one canonical queue per device,
and you normally work with this queue implicitly. However, you can always create as many additional queues per device
as needed, and work with them explicitly.</p>
<p>A typical situation when you will want to create the queue explicitly is for profiling purposes.
Read <a class="reference external" href="https://intelpython.github.io/dpctl/latest/index.html">Data Parallel Control</a> documentation for more details about queues.</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><h3>Table of Contents</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="parallelism.html">Parallelism in modern data parallel architectures</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Heterogeneous computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="programming_dpep.html">Programming with Data Parallel Extensions for Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">List of examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="useful_links.html">Useful links</a></li>
<li class="toctree-l1"><a class="reference internal" href="useful_links.html#to-do">To-Do</a></li>
</ul>


<form action="search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="parallelism.html"
                          title="previous chapter">Parallelism in modern data parallel architectures</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="programming_dpep.html"
                          title="next chapter">Programming with Data Parallel Extensions for Python</a></p>
  </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
<footer class="footer">
  <p class="pull-right"> &nbsp;
    <a href="#">Back to Top</a></p>
  <p>
    &copy; Copyright 2022, Intel Corporation.<br/>
    Created using <a href="http://www.sphinx-doc.org/en/stable/">Sphinx</a> 6.1.3. &nbsp;
  </p>
</footer>
  </body>
</html>