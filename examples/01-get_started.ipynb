{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a002ea61",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "905c742a",
   "metadata": {},
   "source": [
    "# Changes to Run on GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41bf2099",
   "metadata": {},
   "source": [
    "Below you see the example of how easily, in a few lines of code, switch computations from a CPU to a GPU device.\n",
    "\n",
    "Look on the original example.\n",
    "We allocate 2 matrices on the host (CPU) device usnig the NumPy array function. All future calculations are performed on the allocated host (CPU) device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e8711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res =  [[2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "# Original CPU script\n",
    "\n",
    "# Call numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Data alocated on the CPU device\n",
    "x = np.array([[1, 1], [1, 1]])\n",
    "y = np.array([[1, 1], [1, 1]])\n",
    "\n",
    "# Compute performed on the CPU device, where data is allocated\n",
    "res = np.matmul(x, y)\n",
    "\n",
    "print (\"res = \", res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "402c3d61",
   "metadata": {},
   "source": [
    "Try to modify your code that all calculations occur on the GPU device.\n",
    "\n",
    "To do so, switch to the dpnp library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10b7d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array x is located on the device: Device(level_zero:gpu:0)\n",
      "Array y is located on the device: Device(level_zero:gpu:0)\n",
      "res is located on the device: Device(level_zero:gpu:0)\n",
      "res =  [[2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "# Modified XPU script\n",
    "\n",
    "# Drop-in replacement via single line change\n",
    "import dpnp as np\n",
    "\n",
    "# Data alocated on default SYCL device\n",
    "x = np.array([[1, 1], [1, 1]])\n",
    "y = np.array([[1, 1], [1, 1]])\n",
    "\n",
    "# Compute performed on the device, where data is allocated\n",
    "res = np.matmul(x, y)\n",
    "\n",
    "\n",
    "print (\"Array x is located on the device:\", x.device)\n",
    "print (\"Array y is located on the device:\", y.device)\n",
    "print (\"res is located on the device:\", res.device)\n",
    "print (\"res = \", res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6a58f17",
   "metadata": {},
   "source": [
    "As you see, changing only one line of code helps you perform all calculations on the GPU device.\n",
    "\n",
    "In this example, ``np.array()`` creates an array on the default SYCL* device, which is a \"gpu\" on systems with integrated or discreted GPU (it is \"host\" on systems that do not have GPU). The queue associated with this array is now carried with x and y. ``np.matmul(x, y)`` does matrix product of two arrays x and y. The respective pre-compiled kernel implementing ``np.matmul()`` is submitted to that queue. The result is allocated on the device array associated with that queue. \n",
    "\n",
    "Llet's make a few improvements to your code to see how you can control and specify the device on which you want to perform calculations and which the USM memory type to use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be340585",
   "metadata": {},
   "source": [
    "# dpnp Simple Examples with Popular Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26d8c3c6",
   "metadata": {},
   "source": [
    "1. Example to return an array with evenly spaced values within a given interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0435d7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 µs ± 27.6 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "Result a is located on the device: Device(level_zero:gpu:0)\n",
      "a =  [ 3  9 15 21 27]\n"
     ]
    }
   ],
   "source": [
    "import dpnp as np\n",
    "\n",
    "# Create an array of values from 3 till 30 with step 6\n",
    "a = np.arange(3, 30, step = 6)\n",
    "\n",
    "print (\"Result a is located on the device:\", a.device)\n",
    "print (\"a = \", a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6765095",
   "metadata": {},
   "source": [
    "In this example, ``np.arange()`` creates an array on the default SYCL* device, which is a \"gpu\" on systems with integrated or discrete GPU (it is \"host\" on systems that do not have GPU)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35081461",
   "metadata": {},
   "source": [
    "2. Example that calculates the sum of the array elements on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e613398f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result x is located on the device: Device(level_zero:gpu:0)\n",
      "Result y is located on the device: Device(level_zero:gpu:0)\n",
      "The sum of the array elements is:  6\n"
     ]
    }
   ],
   "source": [
    "import dpnp as np\n",
    "\n",
    "x = np.empty(3)\n",
    "\n",
    "try:\n",
    "    # Using filter selector strings to specify root devices for a new array\n",
    "    x = np.asarray ([1, 2, 3], device=\"gpu\")\n",
    "    print (\"Result x is located on the device:\", x.device)\n",
    "except:\n",
    "    print (\"GPU device is not available\")\n",
    "\n",
    "# Return the sum of the array elements\n",
    "y = np.sum (x) # Expect 6\n",
    "\n",
    "print (\"Result y is located on the device:\", y.device)\n",
    "print (\"The sum of the array elements is: \", y )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b4915e",
   "metadata": {},
   "source": [
    "In this example, ``np.asarray()`` creates an array on the default GPU device. The queue associated with this array is now carried with x. ``np.sum(x)`` derives it from x, and respective pre-compiled kernel implementing ``np.sum()`` is submitted to that queue. The result y is allocated on the device 0-dimensional array associated with that queue too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f4c62",
   "metadata": {},
   "source": [
    "3. Example of inversion of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b53afed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array a is located on the device: Device(level_zero:gpu:0)\n",
      "Result x is located on the device: Device(level_zero:gpu:0)\n",
      "Array x is: [[-2 -2]\n",
      " [-3 -2]\n",
      " [-2 -1]\n",
      " [ 0 -1]]\n"
     ]
    }
   ],
   "source": [
    "import dpnp as np\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Using filter selector strings to specify root devices for an array\n",
    "    a = np.array([[1, 1], [2, 1], [1, 0], [-1, 0]], device = \"gpu\")\n",
    "    print (\"Array a is located on the device:\", a.device)  \n",
    "\n",
    "    # Do inversion of an array \"a\"\n",
    "    x = np.invert(a)\n",
    "\n",
    "    print (\"Result x is located on the device:\", x.device)\n",
    "    print (\"Array x is:\", x) \n",
    "\n",
    "except:\n",
    "    print (\"GPU device is not available\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e10f226a",
   "metadata": {},
   "source": [
    "In this example, ``np.array()`` creates an array on the default GPU device. The queue associated with this array is now carried with a. ``np.invert(a)`` derives it from a, and respective pre-compiled kernel implementing ``np.invert()`` is submitted to that queue. The result x is allocated on the device array associated with that queue too."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94cb3b9b",
   "metadata": {},
   "source": [
    "# dpctl Simple Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fb4b1b5",
   "metadata": {},
   "source": [
    "Here you may find a list of simple examples. They explain how to understand how many devices you have on a system and how to operate with them.\n",
    "\n",
    "Let's print the list of all available SYCL devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b890ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel(R) OpenCL HD Graphics OpenCL 3.0 \n",
      "Intel(R) FPGA Emulation Platform for OpenCL(TM) OpenCL 1.2 Intel(R) FPGA SDK for OpenCL(TM), Version 20.3\n",
      "Intel(R) OpenCL OpenCL 3.0 WINDOWS\n",
      "Intel(R) Level-Zero 1.3\n"
     ]
    }
   ],
   "source": [
    "# See the list of available SYCL platforms and extra metadata about each platform.\n",
    "import dpctl\n",
    "\n",
    "dpctl.lsplatform()  # Print platform information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db5e8db4",
   "metadata": {},
   "source": [
    "On the platform used for the example, OpenCL GPU driver, Intel(R) FPGA Emulation Device, OpenCL CPU driver, and Level Zero GPU driver are available.\n",
    "\n",
    "To get more information about devices you have, change verbocity parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcf0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform  0 ::\n",
      "    Name        Intel(R) OpenCL HD Graphics\n",
      "    Version     OpenCL 3.0 \n",
      "    Vendor      Intel(R) Corporation\n",
      "    Backend     opencl\n",
      "    Num Devices 1\n",
      "      # 0\n",
      "        Name                Intel(R) Iris(R) Xe Graphics\n",
      "        Version             31.0.101.3430\n",
      "        Filter string       opencl:gpu:0\n",
      "Platform  1 ::\n",
      "    Name        Intel(R) FPGA Emulation Platform for OpenCL(TM)\n",
      "    Version     OpenCL 1.2 Intel(R) FPGA SDK for OpenCL(TM), Version 20.3\n",
      "    Vendor      Intel(R) Corporation\n",
      "    Backend     opencl\n",
      "    Num Devices 1\n",
      "      # 0\n",
      "        Name                Intel(R) FPGA Emulation Device\n",
      "        Version             2022.15.11.0.18_160000\n",
      "        Filter string       opencl:accelerator:0\n",
      "Platform  2 ::\n",
      "    Name        Intel(R) OpenCL\n",
      "    Version     OpenCL 3.0 WINDOWS\n",
      "    Vendor      Intel(R) Corporation\n",
      "    Backend     opencl\n",
      "    Num Devices 1\n",
      "      # 0\n",
      "        Name                11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz\n",
      "        Version             2022.15.11.0.18_160000\n",
      "        Filter string       opencl:cpu:0\n",
      "Platform  3 ::\n",
      "    Name        Intel(R) Level-Zero\n",
      "    Version     1.3\n",
      "    Vendor      Intel(R) Corporation\n",
      "    Backend     ext_oneapi_level_zero\n",
      "    Num Devices 1\n",
      "      # 0\n",
      "        Name                Intel(R) Iris(R) Xe Graphics\n",
      "        Version             1.3.23904\n",
      "        Filter string       level_zero:gpu:0\n"
     ]
    }
   ],
   "source": [
    "# See the list of available SYCL platforms and extra metadata about each platform.\n",
    "import dpctl\n",
    "\n",
    "dpctl.lsplatform(2)  # Print platform information with verbocitz level 2 (highest level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f63525d3",
   "metadata": {},
   "source": [
    "Knowing information about available SYCL platforms, you can specify which type of devices you want to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ff47e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<dpctl.SyclDevice [backend_type.opencl, device_type.gpu,  Intel(R) Iris(R) Xe Graphics] at 0x1a1eddd72f0>, <dpctl.SyclDevice [backend_type.level_zero, device_type.gpu,  Intel(R) Iris(R) Xe Graphics] at 0x1a1eddd70f0>]\n"
     ]
    }
   ],
   "source": [
    "# See the list of available gpu devices and their extra metadata.\n",
    "import dpctl\n",
    "\n",
    "if dpctl.has_gpu_devices():\n",
    "    print (dpctl.get_devices(device_type='gpu'))\n",
    "else:\n",
    "    print(\"GPU device is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93e7cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<dpctl.SyclDevice [backend_type.opencl, device_type.cpu,  11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz] at 0x1779083bcf0>]\n"
     ]
    }
   ],
   "source": [
    "# See the list of available gpu devices and their extra metadata.\n",
    "import dpctl\n",
    "\n",
    "if dpctl.has_cpu_devices():\n",
    "    print (dpctl.get_devices(device_type='cpu'))\n",
    "else:\n",
    "    print(\"CPU device is not available\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efcc3f45",
   "metadata": {},
   "source": [
    "You can also make selection of the specific device on your system using the default selctor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c068447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name            Intel(R) Iris(R) Xe Graphics\n",
      "    Driver version  1.3.23904\n",
      "    Vendor          Intel(R) Corporation\n",
      "    Filter string   level_zero:gpu:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dpctl\n",
    "\n",
    "try:\n",
    "    # Create a SyclDevice of type GPU based on whatever is returned\n",
    "    # by the SYCL `gpu_selector` device selector class.\n",
    "    gpu = dpctl.select_gpu_device()\n",
    "    gpu.print_device_info() # print GPU device information\n",
    "\n",
    "except:\n",
    "    print (\"GPU device is not available\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c378b79d",
   "metadata": {},
   "source": [
    "By using the infromation in filter string of the device, you can create an explicit SyclDevice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad83abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name            Intel(R) Iris(R) Xe Graphics\n",
      "    Driver version  1.3.23904\n",
      "    Vendor          Intel(R) Corporation\n",
      "    Profile         FULL_PROFILE\n",
      "    Filter string   level_zero:gpu:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dpctl\n",
    "\n",
    "# Create a SyclDevice with an explicit filter string,\n",
    "# in this case the first level_zero gpu device.\n",
    "try:\n",
    "    level_zero_gpu = dpctl.SyclDevice(\"level_zero:gpu:0\")\n",
    "    level_zero_gpu.print_device_info()\n",
    "except:\n",
    "    print(\"The first level_zero GPU device is not available\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eadefe0b",
   "metadata": {},
   "source": [
    "To check if your gpu device support double precision, selcet a GPU device and check the ``has_aspect_fp64`` parameter :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a94756d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name            Intel(R) Iris(R) Xe Graphics\n",
      "    Driver version  1.3.23904\n",
      "    Vendor          Intel(R) Corporation\n",
      "    Filter string   level_zero:gpu:0\n",
      "\n",
      "Double precision support is False\n"
     ]
    }
   ],
   "source": [
    "import dpctl\n",
    "# Select GPU device and check double precision support\n",
    "try:\n",
    "    gpu = dpctl.select_gpu_device()\n",
    "    gpu.print_device_info()\n",
    "    print(\"Double precision support is\", gpu.has_aspect_fp64)\n",
    "except:\n",
    "    print(\"The GPU device is not available\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
